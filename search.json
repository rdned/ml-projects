[
  {
    "objectID": "project-proposals/time-series-db.html",
    "href": "project-proposals/time-series-db.html",
    "title": "Time Series Database",
    "section": "",
    "text": "We have data that represent videos of facial heatmaps. These data are time series of 2D matrices, the shape of which is a function of time. To store such data, we employ TimescaleDB, which is an extension of PostgreSQL, a relational DBMS optimized for time-series data.1\nWe have developed an API to access the data. The API is implemented in Python using Psycopg2 library, which is a popular PostgreSQL adapter for Python. The API allows needed data manipulation operations. In our pipeline, we retrieve the data from the database, and calculate other so-called derived features like mean, standard deviation, skewness, kurtosis, normalized-size heatmaps, discrete 2D wavelet transform etc. locally in Python.",
    "crumbs": [
      "Task proposals",
      "Time series DB"
    ]
  },
  {
    "objectID": "project-proposals/time-series-db.html#problem-statement",
    "href": "project-proposals/time-series-db.html#problem-statement",
    "title": "Time Series Database",
    "section": "",
    "text": "We have data that represent videos of facial heatmaps. These data are time series of 2D matrices, the shape of which is a function of time. To store such data, we employ TimescaleDB, which is an extension of PostgreSQL, a relational DBMS optimized for time-series data.1\nWe have developed an API to access the data. The API is implemented in Python using Psycopg2 library, which is a popular PostgreSQL adapter for Python. The API allows needed data manipulation operations. In our pipeline, we retrieve the data from the database, and calculate other so-called derived features like mean, standard deviation, skewness, kurtosis, normalized-size heatmaps, discrete 2D wavelet transform etc. locally in Python.",
    "crumbs": [
      "Task proposals",
      "Time series DB"
    ]
  },
  {
    "objectID": "project-proposals/time-series-db.html#suggestions",
    "href": "project-proposals/time-series-db.html#suggestions",
    "title": "Time Series Database",
    "section": "Suggestions",
    "text": "Suggestions\nWe can define a more complex database schema that includes integrity constraints and triggers. The goal is to ensure data consistency and automate the calculation and storage of derived features within the DBMS. This approach eliminates the need to derive these features each time the ‘basic’ data is retrieved, enhancing efficiency and reliability.",
    "crumbs": [
      "Task proposals",
      "Time series DB"
    ]
  },
  {
    "objectID": "project-proposals/time-series-db.html#footnotes",
    "href": "project-proposals/time-series-db.html#footnotes",
    "title": "Time Series Database",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe could also consider using a different DB like InfluxDB or Prometheus.↩︎",
    "crumbs": [
      "Task proposals",
      "Time series DB"
    ]
  },
  {
    "objectID": "project-proposals/time-series-modelling.html",
    "href": "project-proposals/time-series-modelling.html",
    "title": "Time Series Modelling",
    "section": "",
    "text": "We propose a hypothesis suggesting a causal association between two stochastic processes, each operating within its own distinct state space with differing dimensions. The first process involves thermocamera video capturing faces, while the second involves music recording.\nThe aim is to estimate the intensity of the causal association by comparing the self-forecasting of the first process with its forecasting that also incorporates insights from the second process. If the latter demonstrates superior performance, it could indicate a causal association between the two processes.1",
    "crumbs": [
      "Task proposals",
      "Time series modelling"
    ]
  },
  {
    "objectID": "project-proposals/time-series-modelling.html#problem-statement",
    "href": "project-proposals/time-series-modelling.html#problem-statement",
    "title": "Time Series Modelling",
    "section": "",
    "text": "We propose a hypothesis suggesting a causal association between two stochastic processes, each operating within its own distinct state space with differing dimensions. The first process involves thermocamera video capturing faces, while the second involves music recording.\nThe aim is to estimate the intensity of the causal association by comparing the self-forecasting of the first process with its forecasting that also incorporates insights from the second process. If the latter demonstrates superior performance, it could indicate a causal association between the two processes.1",
    "crumbs": [
      "Task proposals",
      "Time series modelling"
    ]
  },
  {
    "objectID": "project-proposals/time-series-modelling.html#suggestions",
    "href": "project-proposals/time-series-modelling.html#suggestions",
    "title": "Time Series Modelling",
    "section": "Suggestions",
    "text": "Suggestions\nWe suggest using a long sequence time forecasting model with a transformer architecture, which has proven effective in handling complex time dependencies in time series data. Specifically, Autoformer and Informer are hot candidates: they are both open source, available on HuggingFace Hub of Git-based repos, and can be relatively easily adapted to our needs.\nNote that causal inference assumes unconfoundedness of the two processes. In general, unconfoundedness is a strong assumption necessary for making causal inferences. However, in our case, it is a reasonable assumption, excluding hidden variables that significantly influence both processes. For example, a potential confounder could be tiredness if it strongly impacts both the opera director/singers/musicians and the audience. In such case, we would need to adjust for it, which is a standard approach in causal inference from observational data.",
    "crumbs": [
      "Task proposals",
      "Time series modelling"
    ]
  },
  {
    "objectID": "project-proposals/time-series-modelling.html#footnotes",
    "href": "project-proposals/time-series-modelling.html#footnotes",
    "title": "Time Series Modelling",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is supported by chain rule for entropy: \\(H(X)=I(X;Y)+H(X∣Y)\\), and rests also on the assumption that an opera performance is highly unlikely to be influenced by its audience.↩︎",
    "crumbs": [
      "Task proposals",
      "Time series modelling"
    ]
  },
  {
    "objectID": "project-proposals/face-tracking.html",
    "href": "project-proposals/face-tracking.html",
    "title": "Face Tracking",
    "section": "",
    "text": "This is a typical computer vision task. The goal is to improve the performance of the face tracking algorithm (see the video below). The algorithm is implemented in Python using OpenCV. Current version exploits thresholding segmentation and tracking based on simple features like energy and velocity vector.\n\n\nYour browser does not support the video tag.",
    "crumbs": [
      "Task proposals",
      "Face tracking"
    ]
  },
  {
    "objectID": "project-proposals/face-tracking.html#problem-statement",
    "href": "project-proposals/face-tracking.html#problem-statement",
    "title": "Face Tracking",
    "section": "",
    "text": "This is a typical computer vision task. The goal is to improve the performance of the face tracking algorithm (see the video below). The algorithm is implemented in Python using OpenCV. Current version exploits thresholding segmentation and tracking based on simple features like energy and velocity vector.\n\n\nYour browser does not support the video tag.",
    "crumbs": [
      "Task proposals",
      "Face tracking"
    ]
  },
  {
    "objectID": "project-proposals/face-tracking.html#suggestions",
    "href": "project-proposals/face-tracking.html#suggestions",
    "title": "Face Tracking",
    "section": "Suggestions",
    "text": "Suggestions\nOne may consider other types of segmentation like edge-based segmentation. As for tracking, one may try a simple SORT algorithm using Kalman filter.\n\nMore ambitious ideas\n\nSuper resolution and face normalization\n\nIn ideal case, we would like to perform face normalization. However this is a very challenging task due to a very low resolution of our video data. We would need faces to be at least 60 x 90 pixels. To increase the resolution, we may consider using a super-resolution algorithm.1",
    "crumbs": [
      "Task proposals",
      "Face tracking"
    ]
  },
  {
    "objectID": "project-proposals/face-tracking.html#footnotes",
    "href": "project-proposals/face-tracking.html#footnotes",
    "title": "Face Tracking",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor example, Azure OpenAI can leverage models like GPT-4 and DALL-E to enhance the resolution of thermal images, making them clearer and more detailed.↩︎",
    "crumbs": [
      "Task proposals",
      "Face tracking"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Influence of Art on Brain Activity",
    "section": "",
    "text": "This webpage is dedicated to an innovative research project exploring the profound influence of musical stimuli on brain activity. Specifically, we immerse participants in the experience of full-length lyric operas, harnessing their rich musical and narrative complexity to study how these masterpieces engage the human mind.\nWe hypothesize that changes in skin temperature provide a reliable proxy for the impact of artistic stimuli on brain activity. Using a high-sensitivity thermocamera, we record videos of participants as they experience opera performances. These recordings allow us to track detailed facial heatmaps, capturing physiological responses over the duration of the performance.\nThe goal of this project is to uncover how complete operatic works influence brain activity, helping us identify strong musical triggers and enabling a deeper understanding of the human brain. This research can unlock insights into the cognitive and emotional processes shaped by art and contribute to fields such as neuroscience, psychology, and personalized artistic engagement.\nThe practical applications are wide-ranging. In healthcare, the findings may inspire personalized therapeutic interventions for conditions like stress, anxiety, and rehabilitation. In the realm of show business, they could inform the creation of immersive performances that maximize emotional resonance and audience engagement.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Influence of Art on Brain Activity",
    "section": "",
    "text": "This webpage is dedicated to an innovative research project exploring the profound influence of musical stimuli on brain activity. Specifically, we immerse participants in the experience of full-length lyric operas, harnessing their rich musical and narrative complexity to study how these masterpieces engage the human mind.\nWe hypothesize that changes in skin temperature provide a reliable proxy for the impact of artistic stimuli on brain activity. Using a high-sensitivity thermocamera, we record videos of participants as they experience opera performances. These recordings allow us to track detailed facial heatmaps, capturing physiological responses over the duration of the performance.\nThe goal of this project is to uncover how complete operatic works influence brain activity, helping us identify strong musical triggers and enabling a deeper understanding of the human brain. This research can unlock insights into the cognitive and emotional processes shaped by art and contribute to fields such as neuroscience, psychology, and personalized artistic engagement.\nThe practical applications are wide-ranging. In healthcare, the findings may inspire personalized therapeutic interventions for conditions like stress, anxiety, and rehabilitation. In the realm of show business, they could inform the creation of immersive performances that maximize emotional resonance and audience engagement.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "python-example.html",
    "href": "python-example.html",
    "title": "Python Example",
    "section": "",
    "text": "This example has some Python code that will be a part of our Quarto site.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "python-example.html#introduction",
    "href": "python-example.html#introduction",
    "title": "Python Example",
    "section": "",
    "text": "This example has some Python code that will be a part of our Quarto site.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "project-proposals/explainable-dl.html",
    "href": "project-proposals/explainable-dl.html",
    "title": "Explainable Deep Learning",
    "section": "",
    "text": "This task builds on the results of the Time series modelling. Specifically, it requires a well trained time series model, the accuracy of which supports our hypothesis of a causal association between musical stimuli and brain activity.\nThe aim is to estimate the quality of the causal association by applying techniques of explainable deep learning. The goal is to understand the model’s decision-making process and to identify the most important features that influence the model’s predictions. This could lead to an improved understanding of the underlying causal mechanisms and identification of strong/main musical triggers of brain activity.",
    "crumbs": [
      "Task proposals",
      "Explainable DL"
    ]
  },
  {
    "objectID": "project-proposals/explainable-dl.html#problem-statement",
    "href": "project-proposals/explainable-dl.html#problem-statement",
    "title": "Explainable Deep Learning",
    "section": "",
    "text": "This task builds on the results of the Time series modelling. Specifically, it requires a well trained time series model, the accuracy of which supports our hypothesis of a causal association between musical stimuli and brain activity.\nThe aim is to estimate the quality of the causal association by applying techniques of explainable deep learning. The goal is to understand the model’s decision-making process and to identify the most important features that influence the model’s predictions. This could lead to an improved understanding of the underlying causal mechanisms and identification of strong/main musical triggers of brain activity.",
    "crumbs": [
      "Task proposals",
      "Explainable DL"
    ]
  },
  {
    "objectID": "project-proposals/explainable-dl.html#suggestions",
    "href": "project-proposals/explainable-dl.html#suggestions",
    "title": "Explainable Deep Learning",
    "section": "Suggestions",
    "text": "Suggestions\nConsider using the following techniques:\n\nClass activation maps (CAM) to visualize the most important regions of the input data (in music state space) that contribute to the model’s prediction (in facial temperature features state space).\nPerturbation based methods to evaluate the robustness of the model’s predictions. For example, perturb the input data and observe how the model’s predictions change. This could help identify the most sensitive regions of the input data.\nAttention weights visualization to provide insights into which parts of the input the model is paying attention to.\nTrend and Seasonal Decomposition: Autoformer model, for example, uses decomposition layers to separate trend and seasonal components. Visualizing these components can help understand how the model captures different aspects of the time-series data.",
    "crumbs": [
      "Task proposals",
      "Explainable DL"
    ]
  },
  {
    "objectID": "project-proposals/vc-dimension.html",
    "href": "project-proposals/vc-dimension.html",
    "title": "Vapnik–Chervonenkis Dimension",
    "section": "",
    "text": "We define a parametric space of stochastic processes1 so that a stochastic process realization (sample path) is a result of a composition of a time vector function,2 1D wavelet transform on each chanel of the time vector function, and a (possibly) non-linear dimensionality reduction.3\nIn our project, the parametric space of stochastic processes plays the role of a statistical classification model. VC dimension of the model is important as it measures its capacity, which helps to estimate the model’s generalization error. The goal is to find a balance where the model is complex enough to capture the underlying patterns but not so complex that it overfits the data.",
    "crumbs": [
      "Task proposals",
      "VC dimension"
    ]
  },
  {
    "objectID": "project-proposals/vc-dimension.html#problem-statement",
    "href": "project-proposals/vc-dimension.html#problem-statement",
    "title": "Vapnik–Chervonenkis Dimension",
    "section": "",
    "text": "We define a parametric space of stochastic processes1 so that a stochastic process realization (sample path) is a result of a composition of a time vector function,2 1D wavelet transform on each chanel of the time vector function, and a (possibly) non-linear dimensionality reduction.3\nIn our project, the parametric space of stochastic processes plays the role of a statistical classification model. VC dimension of the model is important as it measures its capacity, which helps to estimate the model’s generalization error. The goal is to find a balance where the model is complex enough to capture the underlying patterns but not so complex that it overfits the data.",
    "crumbs": [
      "Task proposals",
      "VC dimension"
    ]
  },
  {
    "objectID": "project-proposals/vc-dimension.html#suggestions",
    "href": "project-proposals/vc-dimension.html#suggestions",
    "title": "Vapnik–Chervonenkis Dimension",
    "section": "Suggestions",
    "text": "Suggestions\nThis task is challenging due to the complexity of the model. It requires a rigorous mathematical analysis, which involves proving whether a set of points can be shattered by the hypothesis space. This is non-trivial, and moreover, can be computationally very intensive!",
    "crumbs": [
      "Task proposals",
      "VC dimension"
    ]
  },
  {
    "objectID": "project-proposals/vc-dimension.html#footnotes",
    "href": "project-proposals/vc-dimension.html#footnotes",
    "title": "Vapnik–Chervonenkis Dimension",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis function space is analogous to a feature encoding space in a supervised learning.↩︎\nA time vector function may be defined as a result of a discrete 2D wavelet transform applied to heatmap matrices in every time point↩︎\nFor example, a non-linear ICA implemented as CEBRA↩︎",
    "crumbs": [
      "Task proposals",
      "VC dimension"
    ]
  }
]