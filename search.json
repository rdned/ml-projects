[
  {
    "objectID": "project-proposals/time-series-db.html",
    "href": "project-proposals/time-series-db.html",
    "title": "Time Series Database",
    "section": "",
    "text": "We have data that represent videos of facial heatmaps. These data are time series of 2D matrices, the shape of which is a function of time. To store such data, we employ TimescaleDB, which is an extension of PostgreSQL, a relational DBMS optimized for time-series data.1\nWe have developed an API to access the data. The API is implemented in Python using Psycopg2 library, which is a popular PostgreSQL adapter for Python. The API allows needed data manipulation operations. In our pipeline, we retrieve the data from the database, and calculate other so-called derived features like mean, standard deviation, skewness, kurtosis, normalized-size heatmaps, discrete 2D wavelet transform etc. locally in Python.",
    "crumbs": [
      "Task proposals",
      "Time series DB"
    ]
  },
  {
    "objectID": "project-proposals/time-series-db.html#problem-statement",
    "href": "project-proposals/time-series-db.html#problem-statement",
    "title": "Time Series Database",
    "section": "",
    "text": "We have data that represent videos of facial heatmaps. These data are time series of 2D matrices, the shape of which is a function of time. To store such data, we employ TimescaleDB, which is an extension of PostgreSQL, a relational DBMS optimized for time-series data.1\nWe have developed an API to access the data. The API is implemented in Python using Psycopg2 library, which is a popular PostgreSQL adapter for Python. The API allows needed data manipulation operations. In our pipeline, we retrieve the data from the database, and calculate other so-called derived features like mean, standard deviation, skewness, kurtosis, normalized-size heatmaps, discrete 2D wavelet transform etc. locally in Python.",
    "crumbs": [
      "Task proposals",
      "Time series DB"
    ]
  },
  {
    "objectID": "project-proposals/time-series-db.html#suggestions",
    "href": "project-proposals/time-series-db.html#suggestions",
    "title": "Time Series Database",
    "section": "Suggestions",
    "text": "Suggestions\nWe can define a more complex database schema that includes integrity constraints and triggers. The goal is to ensure data consistency and automate the calculation and storage of derived features within the DBMS. This approach eliminates the need to derive these features each time the ‚Äòbasic‚Äô data is retrieved, enhancing efficiency and reliability.",
    "crumbs": [
      "Task proposals",
      "Time series DB"
    ]
  },
  {
    "objectID": "project-proposals/time-series-db.html#footnotes",
    "href": "project-proposals/time-series-db.html#footnotes",
    "title": "Time Series Database",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe could also consider using a different DB like InfluxDB or Prometheus.‚Ü©Ô∏é",
    "crumbs": [
      "Task proposals",
      "Time series DB"
    ]
  },
  {
    "objectID": "project-proposals/face-tracking.html",
    "href": "project-proposals/face-tracking.html",
    "title": "Face Tracking",
    "section": "",
    "text": "This is a typical computer vision task. The goal is to improve the performance of the face tracking algorithm (see the video below). The algorithm is implemented in Python using OpenCV. Current version exploits thresholding segmentation and tracking based on simple features like energy and velocity vector.\n\n\nYour browser does not support the video tag.",
    "crumbs": [
      "Task proposals",
      "Face tracking"
    ]
  },
  {
    "objectID": "project-proposals/face-tracking.html#problem-statement",
    "href": "project-proposals/face-tracking.html#problem-statement",
    "title": "Face Tracking",
    "section": "",
    "text": "This is a typical computer vision task. The goal is to improve the performance of the face tracking algorithm (see the video below). The algorithm is implemented in Python using OpenCV. Current version exploits thresholding segmentation and tracking based on simple features like energy and velocity vector.\n\n\nYour browser does not support the video tag.",
    "crumbs": [
      "Task proposals",
      "Face tracking"
    ]
  },
  {
    "objectID": "project-proposals/face-tracking.html#suggestions",
    "href": "project-proposals/face-tracking.html#suggestions",
    "title": "Face Tracking",
    "section": "Suggestions",
    "text": "Suggestions\nOne may consider other types of segmentation like edge-based segmentation. As for tracking, one may try a simple SORT algorithm using Kalman filter.\n\nMore ambitious ideas\n\nSuper resolution and face normalization\n\nIn ideal case, we would like to perform face normalization. However this is a very challenging task due to a very low resolution of our video data. We would need faces to be at least 60 x 90 pixels. To increase the resolution, we may consider using a super-resolution algorithm.1",
    "crumbs": [
      "Task proposals",
      "Face tracking"
    ]
  },
  {
    "objectID": "project-proposals/face-tracking.html#footnotes",
    "href": "project-proposals/face-tracking.html#footnotes",
    "title": "Face Tracking",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor example, Azure OpenAI can leverage models like GPT-4 and DALL-E to enhance the resolution of thermal images, making them clearer and more detailed.‚Ü©Ô∏é",
    "crumbs": [
      "Task proposals",
      "Face tracking"
    ]
  },
  {
    "objectID": "project-proposals/vc-dimension.html",
    "href": "project-proposals/vc-dimension.html",
    "title": "Vapnik‚ÄìChervonenkis Dimension",
    "section": "",
    "text": "We define a parametric space of stochastic processes (analogous to a feature‚Äëencoding space in supervised learning) so that a stochastic process realization (sample path) is produced by the composition of three stages:\n\nTime vector map that converts raw inputs (e.g., a sequence of heatmap matrices) into a per‚Äëtime vector representation.\n\n1‚ÄëD temporal wavelet transform applied to each channel of the time vector, producing multiscale, time‚Äìfrequency localized coefficients.\n\nSequencewise dimensionality reduction (possibly nonlinear, e.g., nonlinear ICA / CEBRA) that maps the multiscale coefficients to a lower‚Äëdimensional sequence representation.\n\nFor more formal exposition refer to the Compute heatmap modelling.\nIn our project, the parametric space of stochastic processes plays the role of a statistical classification model. VC dimension of the model is important as it measures its capacity, which helps to estimate the model‚Äôs generalization error. The goal is to find a balance where the model is complex enough to capture the underlying patterns but not so complex that it overfits the data.",
    "crumbs": [
      "Task proposals",
      "VC dimension"
    ]
  },
  {
    "objectID": "project-proposals/vc-dimension.html#problem-statement",
    "href": "project-proposals/vc-dimension.html#problem-statement",
    "title": "Vapnik‚ÄìChervonenkis Dimension",
    "section": "",
    "text": "We define a parametric space of stochastic processes (analogous to a feature‚Äëencoding space in supervised learning) so that a stochastic process realization (sample path) is produced by the composition of three stages:\n\nTime vector map that converts raw inputs (e.g., a sequence of heatmap matrices) into a per‚Äëtime vector representation.\n\n1‚ÄëD temporal wavelet transform applied to each channel of the time vector, producing multiscale, time‚Äìfrequency localized coefficients.\n\nSequencewise dimensionality reduction (possibly nonlinear, e.g., nonlinear ICA / CEBRA) that maps the multiscale coefficients to a lower‚Äëdimensional sequence representation.\n\nFor more formal exposition refer to the Compute heatmap modelling.\nIn our project, the parametric space of stochastic processes plays the role of a statistical classification model. VC dimension of the model is important as it measures its capacity, which helps to estimate the model‚Äôs generalization error. The goal is to find a balance where the model is complex enough to capture the underlying patterns but not so complex that it overfits the data.",
    "crumbs": [
      "Task proposals",
      "VC dimension"
    ]
  },
  {
    "objectID": "project-proposals/vc-dimension.html#suggestions",
    "href": "project-proposals/vc-dimension.html#suggestions",
    "title": "Vapnik‚ÄìChervonenkis Dimension",
    "section": "Suggestions",
    "text": "Suggestions\nThis task is challenging due to the complexity of the model. It requires a rigorous mathematical analysis, which involves proving whether a set of points can be shattered by the hypothesis space. This is non-trivial, and moreover, can be computationally very intensive!",
    "crumbs": [
      "Task proposals",
      "VC dimension"
    ]
  },
  {
    "objectID": "methodology/tracking.html",
    "href": "methodology/tracking.html",
    "title": "Track individual heatmaps",
    "section": "",
    "text": "For more detail see Face tracking",
    "crumbs": [
      "Methodology",
      "Track individual heatmaps"
    ]
  },
  {
    "objectID": "methodology/dbms.html",
    "href": "methodology/dbms.html",
    "title": "Store in DBMS",
    "section": "",
    "text": "For more details see Time series DB",
    "crumbs": [
      "Methodology",
      "Store in DBMS"
    ]
  },
  {
    "objectID": "methodology/Methodology.html",
    "href": "methodology/Methodology.html",
    "title": "Methodology",
    "section": "",
    "text": "%%| fig-cap: \"Swimlane Diagram: Multimodal Music‚ÄìEmotion Workflow ‚Äî vertical lanes, all top-down\"\nflowchart TD\n\n  %% --- Audience: Heatmap Tracking (top-down) ---\n  subgraph AUD_TRACK[\"üé≠ Heatmap Tracking\"]\n    direction TB\n    A1[\"Track individual heatmaps\"]\n    A1b[(üóÑÔ∏è Store in a DBMS)]\n  end\n\n  %% --- Audience: Heatmap Embedding (top-down) ---\n  subgraph AUD_EMB[\"üé≠ Heatmap Embedding\"]\n    direction TB\n    A2[\"Compute heatmap embeddings\"]\n    A3[\"Extract denoised emotional signals\"]\n  end\n\n  %% --- Audio (top-down) ---\n  subgraph AUDIO[\"üéµ Audio Embedding\"]\n    direction TB\n    B1[\"Model audio as stochastic process\"]\n    B2[\"Compute synchronized audio embeddings\"]\n  end\n\n  %% --- Model (top-down) ---\n  subgraph MODEL[\"üß† Connecting Music and Emotions\"]\n    direction TB\n    C1[\"Implement and train ANN\"]\n    C2[\"Evaluate causal influence\"]\n  end\n\n  %% --- XAI (top-down) ---\n  subgraph XAI[\"‚ú® Explainable AI Analysis\"]\n    direction TB\n    D1[\"Apply XAI methods\"]\n    D2[\"Identify influential features\"]\n    D3[\"Interpret emotional influence\"]\n  end\n\n  %% --- Vertical ordering (stacked lanes, top ‚Üí down) ---\n  %%AUD_TRACK --&gt; AUD_EMB\n  %%AUD_EMB --&gt; AUDIO\n  %%AUDIO --&gt; MODEL\n  %%MODEL --&gt; XAI\n\n  %% --- Internal top-down flows ---\n  A1 --&gt; A1b\n  A1b --&gt; A2\n  A2 --&gt; A3\n  A3 --&gt; C1\n  B1 --&gt; B2\n  B2 --&gt; C1\n  C1 --&gt; C2\n  C2 --&gt; D1\n  D1 --&gt; D2\n  D2 --&gt; D3\n\n  %% --- Styling ---\n  classDef audienceStyle fill:#F8FBFF,stroke:#0277bd,stroke-width:2px,color:#000\n  classDef embStyle fill:#e8f4ff,stroke:#0277bd,stroke-width:2px,color:#000\n  classDef audioStyle fill:#e8ffe8,stroke:#00796b,stroke-width:2px,color:#000\n  classDef modelStyle fill:#fff9d6,stroke:#f57f17,stroke-width:2px,color:#000\n  classDef xaiStyle fill:#f7e8ff,stroke:#6a1b9a,stroke-width:2px,color:#000\n  classDef nodeStyle fill:#ffffff,stroke:#333,stroke-width:1px,color:#000\n\n\n  class AUD_TRACK audienceStyle\n  class AUD_EMB embStyle\n  class AUDIO audioStyle\n  class MODEL modelStyle\n  class XAI xaiStyle\n  class A1,A1b,A2,A3,B1,B2,C1,C2,D1,D2,D3 node",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "methodology/Methodology.html#expected-outcomes",
    "href": "methodology/Methodology.html#expected-outcomes",
    "title": "Methodology",
    "section": "Expected Outcomes",
    "text": "Expected Outcomes\n\n\n\n\n\n\n\nA robust model linking musical features to emotional reactions\nUnderstanding of temporal dynamics of emotions during live music\nExplainable insights into causal relationships between music and emotions",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "methodology/Methodology.html#future-work",
    "href": "methodology/Methodology.html#future-work",
    "title": "Methodology",
    "section": "Future Work",
    "text": "Future Work\n\nExtend to other music genres and live settings\nIncorporate physiological data for multimodal emotion analysis\nRefine models with larger datasets and advanced AI techniques",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "Methodology.html",
    "href": "Methodology.html",
    "title": "Methodology",
    "section": "",
    "text": "%%| fig-cap: \"Swimlane Diagram: Multimodal Music‚ÄìEmotion Workflow\"\nflowchart LR\n\n    %% --- Audience Lane ---\n    subgraph AUDIENCE[\"üé≠ Heatmap Tracking\"]\n        direction TB\n        A1[\"Track individual heatmaps\"]\n        A2[\"Compute heatmap embeddings\"]\n        A3[\"Extract denoised emotional signals\"]\n    end\n\n    %% --- Audio Lane ---\n    subgraph AUDIO[\"üéµ Audio Embedding\"]\n        direction TB\n        B1[\"Compute synchronized audio embeddings\"]\n        B2[\"Model audio as stochastic process\"]\n    end\n\n    %% --- Model Lane ---\n    subgraph MODEL[\"üß† Connecting Music and Emotions\"]\n        direction TB\n        C1[\"Implement and train ANN\"]\n        C3[\"Evaluate causal influence\"]\n    end\n\n    %% --- XAI Lane ---\n    subgraph XAI[\"‚ú® Explainable AI Analysis\"]\n        direction TB\n        D1[\"Apply XAI methods\"]\n        D2[\"Identify influential features\"]\n        D3[\"Interpret emotional influence\"]\n    end\n\n    %% --- Cross‚Äëlane flows ---\n    A3 --&gt; C1\n    B2 --&gt; C1\n    C3 --&gt; D1\n\n    %% --- Styling ---\n    classDef audienceStyle fill:#e8f4ff,stroke:#0277bd,stroke-width:2px,color:#000\n    classDef audioStyle fill:#e8ffe8,stroke:#00796b,stroke-width:2px,color:#000\n    classDef modelStyle fill:#fff9d6,stroke:#f57f17,stroke-width:2px,color:#000\n    classDef xaiStyle fill:#f7e8ff,stroke:#6a1b9a,stroke-width:2px,color:#000\n    classDef nodeStyle fill:#ffffff,stroke:#333,stroke-width:1px,color:#000\n\n    class AUDIENCE audienceStyle\n    class AUDIO audioStyle\n    class MODEL modelStyle\n    class XAI xaiStyle\n    class A1,A2,A3,B1,B2,C1,C3,D1,D2,D3 nodeStyle\n\n\n\n\n\n\n\n\n\n\nTrack individual heatmaps corresponding to individual faces in the audience during the opera\nCalculate embeddings for each tracked heatmap representing stochastic processes\nExtract stochastic processes that minimize noise while preserving emotional information related to emotions during listening\n\n\n\n\n\nCalculate embeddings of the synchronized audio from the opera\nModel the audio embedding as a stochastic process capturing musical features influencing emotions\n\n\n\n\n\nImplement an Artificial Neural Network (ANN) to connect the stochastic processes from audience emotions and music\nTrain the ANN to predict emotions from music features and previous emotional states\nHypothesize causal influence of music on emotions based on prediction accuracy\n\n\n\n\n\nApply explainable AI methods to the trained ANN\nIdentify crucial input features (music or previous emotions) that drive emotion prediction\nGain insights into how music influences emotional responses"
  },
  {
    "objectID": "Methodology.html#methodology",
    "href": "Methodology.html#methodology",
    "title": "Methodology",
    "section": "",
    "text": "%%| fig-cap: \"Swimlane Diagram: Multimodal Music‚ÄìEmotion Workflow\"\nflowchart LR\n\n    %% --- Audience Lane ---\n    subgraph AUDIENCE[\"üé≠ Heatmap Tracking\"]\n        direction TB\n        A1[\"Track individual heatmaps\"]\n        A2[\"Compute heatmap embeddings\"]\n        A3[\"Extract denoised emotional signals\"]\n    end\n\n    %% --- Audio Lane ---\n    subgraph AUDIO[\"üéµ Audio Embedding\"]\n        direction TB\n        B1[\"Compute synchronized audio embeddings\"]\n        B2[\"Model audio as stochastic process\"]\n    end\n\n    %% --- Model Lane ---\n    subgraph MODEL[\"üß† Connecting Music and Emotions\"]\n        direction TB\n        C1[\"Implement and train ANN\"]\n        C3[\"Evaluate causal influence\"]\n    end\n\n    %% --- XAI Lane ---\n    subgraph XAI[\"‚ú® Explainable AI Analysis\"]\n        direction TB\n        D1[\"Apply XAI methods\"]\n        D2[\"Identify influential features\"]\n        D3[\"Interpret emotional influence\"]\n    end\n\n    %% --- Cross‚Äëlane flows ---\n    A3 --&gt; C1\n    B2 --&gt; C1\n    C3 --&gt; D1\n\n    %% --- Styling ---\n    classDef audienceStyle fill:#e8f4ff,stroke:#0277bd,stroke-width:2px,color:#000\n    classDef audioStyle fill:#e8ffe8,stroke:#00796b,stroke-width:2px,color:#000\n    classDef modelStyle fill:#fff9d6,stroke:#f57f17,stroke-width:2px,color:#000\n    classDef xaiStyle fill:#f7e8ff,stroke:#6a1b9a,stroke-width:2px,color:#000\n    classDef nodeStyle fill:#ffffff,stroke:#333,stroke-width:1px,color:#000\n\n    class AUDIENCE audienceStyle\n    class AUDIO audioStyle\n    class MODEL modelStyle\n    class XAI xaiStyle\n    class A1,A2,A3,B1,B2,C1,C3,D1,D2,D3 nodeStyle\n\n\n\n\n\n\n\n\n\n\nTrack individual heatmaps corresponding to individual faces in the audience during the opera\nCalculate embeddings for each tracked heatmap representing stochastic processes\nExtract stochastic processes that minimize noise while preserving emotional information related to emotions during listening\n\n\n\n\n\nCalculate embeddings of the synchronized audio from the opera\nModel the audio embedding as a stochastic process capturing musical features influencing emotions\n\n\n\n\n\nImplement an Artificial Neural Network (ANN) to connect the stochastic processes from audience emotions and music\nTrain the ANN to predict emotions from music features and previous emotional states\nHypothesize causal influence of music on emotions based on prediction accuracy\n\n\n\n\n\nApply explainable AI methods to the trained ANN\nIdentify crucial input features (music or previous emotions) that drive emotion prediction\nGain insights into how music influences emotional responses"
  },
  {
    "objectID": "Methodology.html#expected-outcomes",
    "href": "Methodology.html#expected-outcomes",
    "title": "Methodology",
    "section": "Expected Outcomes",
    "text": "Expected Outcomes\n\n\n\n\n\n\n\nA robust model linking musical features to emotional reactions\nUnderstanding of temporal dynamics of emotions during live music\nExplainable insights into causal relationships between music and emotions"
  },
  {
    "objectID": "Methodology.html#future-work",
    "href": "Methodology.html#future-work",
    "title": "Methodology",
    "section": "Future Work",
    "text": "Future Work\n\nExtend to other music genres and live settings\nIncorporate physiological data for multimodal emotion analysis\nRefine models with larger datasets and advanced AI techniques"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Influence of Art on Brain Activity",
    "section": "",
    "text": "This webpage is dedicated to an innovative research project exploring the profound influence of musical stimuli on brain activity. Specifically, we immerse participants in the experience of full-length lyric operas, harnessing their rich musical and narrative complexity to study how these masterpieces engage the human mind.\nWe hypothesize that changes in skin temperature provide a reliable proxy for the impact of artistic stimuli on brain activity. Using a high-sensitivity thermocamera, we record videos of participants as they experience opera performances. These recordings allow us to track detailed facial heatmaps, capturing physiological responses over the duration of the performance.\nThe goal of this project is to uncover how complete operatic works influence brain activity, helping us identify strong musical triggers and enabling a deeper understanding of the human brain. This research can unlock insights into the cognitive and emotional processes shaped by art and contribute to fields such as neuroscience, psychology, and personalized artistic engagement.\nThe practical applications are wide-ranging. In healthcare, the findings may inspire personalized therapeutic interventions for conditions like stress, anxiety, and rehabilitation. In the realm of show business, they could inform the creation of immersive performances that maximize emotional resonance and audience engagement.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Influence of Art on Brain Activity",
    "section": "",
    "text": "This webpage is dedicated to an innovative research project exploring the profound influence of musical stimuli on brain activity. Specifically, we immerse participants in the experience of full-length lyric operas, harnessing their rich musical and narrative complexity to study how these masterpieces engage the human mind.\nWe hypothesize that changes in skin temperature provide a reliable proxy for the impact of artistic stimuli on brain activity. Using a high-sensitivity thermocamera, we record videos of participants as they experience opera performances. These recordings allow us to track detailed facial heatmaps, capturing physiological responses over the duration of the performance.\nThe goal of this project is to uncover how complete operatic works influence brain activity, helping us identify strong musical triggers and enabling a deeper understanding of the human brain. This research can unlock insights into the cognitive and emotional processes shaped by art and contribute to fields such as neuroscience, psychology, and personalized artistic engagement.\nThe practical applications are wide-ranging. In healthcare, the findings may inspire personalized therapeutic interventions for conditions like stress, anxiety, and rehabilitation. In the realm of show business, they could inform the creation of immersive performances that maximize emotional resonance and audience engagement.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "methodology/esignal.html",
    "href": "methodology/esignal.html",
    "title": "Optimization for Denoised Emotional Signal Extraction",
    "section": "",
    "text": "Overview\nWe formulate denoised emotional‚Äësignal extraction as an optimization over a mixed discrete‚Äìcontinuous parameter space \\(\\Theta\\) that parameterizes a \\(p\\)‚Äëdimensional submanifold of a Banach space \\(\\mathcal{M}\\) of maps. Each parameter choice \\(\\theta\\in\\Theta\\) defines a composed encoder\n\\[\n\\Phi_\\theta=\\Psi_\\theta\\circ\\Omega_\\theta\\circ\\mathcal{E}_\\theta,\n\\]\nmapping raw heatmap series \\(X_i(t)\\) to denoised outputs \\(z_i^\\theta(t)\\in\\mathbb{R}^L\\). Categorical design choices such as wavelet family or embedding channel type index continuous submanifolds, so\n\\[\n\\Theta=\\bigcup_{c\\in\\mathcal{C}}\\Theta_c.\n\\]\n\n\n\nModel and notation\n\nRaw data \\(X_i(t)\\) ‚Äî heatmap series for recording \\(i\\), \\(t=1,\\dots,T\\).\n\nTime vector map \\(\\mathcal{E}_\\theta\\) ‚Äî per‚Äëframe preprocessing and channel embedding (categorical choices: percentiles, bin heights, eigencfaces, etc.).\n\nTemporal wavelet operator \\(\\Omega_\\theta\\) ‚Äî 1‚ÄëD wavelet transform along time per channel (categorical choices: wavelet family, levels, padding).\n\nSequencewise encoder \\(\\Psi_\\theta\\) ‚Äî estimator of latent source trajectories under a nonlinear‚ÄëICA model.\n\nBranches \\(c\\in\\mathcal{C}\\) ‚Äî categorical configurations; each branch has continuous parameter manifold \\(\\Theta_c\\).\n\nEncoder output \\(z_i^\\theta(t)=\\Phi_\\theta(X_i)(t)\\in\\mathbb{R}^L\\).\n\n\n\n\nObjectives\nWe support two objective families for learning \\(\\theta\\) (choose one or combine them with weights).\n\nLagged cross correlation objective\n\nPer‚Äëpair normalized lag correlation for scalar sequences \\(a(t),b(t)\\) and lags \\(\\ell\\in[-L_{\\max},L_{\\max}]\\):\n\n\\[\n\\rho_{ab}(\\ell)=\\frac{\\sum_t a(t)\\,b(t+\\ell)}{\\sqrt{\\sum_t a(t)^2}\\sqrt{\\sum_t b(t+\\ell)^2}}.\n\\]\n\nDifferentiable surrogate (soft‚Äëmax over lags with temperature \\(\\beta&gt;0\\)):\n\n\\[\n\\widetilde{\\rho}_{ab}=\\frac{1}{\\beta}\\log\\!\\sum_{\\ell}\\exp\\!\\big(\\beta\\,\\rho_{ab}(\\ell)\\big).\n\\]\n\nObjective to maximize\n\n\\[\n\\mathcal{J}_{\\text{corr}}(\\theta)=\\frac{1}{|\\mathcal{C}|}\\sum_{(i,j)\\in\\mathcal{C}}\\widetilde{\\rho}_{\\,z_i^\\theta,\\,z_j^\\theta}\\;-\\;\\lambda R(\\theta),\n\\]\nwhere \\(\\mathcal{C}\\) is the set of within‚Äësegment pairs and \\(R(\\theta)\\) is a regularizer.\n\n\nDTW classification objective\n\nSoft‚ÄëDTW distance\n\n\\[\nd_{ij} = d_{\\mathrm{sDTW}}\\bigl(z_i^\\theta, z_j^\\theta; \\gamma\\bigr),\n\\]\nwith smoothing \\(\\gamma&gt;0\\).\n\nPair sets: positive pairs \\(\\mathcal P\\); negative pairs \\(\\mathcal N\\).\n\nLogistic model (probabilistic)\n\n\\[\np_{ij}(\\theta) = \\sigma\\!\\Big(\\alpha - w\\frac{d_{ij}}{\\tau}\\Big),\n\\qquad\n\\mathcal L_{\\mathrm{CE}}(\\theta) = -\\sum_{(i,j)}\\bigl[y_{ij}\\log p_{ij} + (1-y_{ij})\\log(1-p_{ij})\\bigr],\n\\]\nwhere \\(y_{ij}\\in\\{0,1\\}\\) and \\(\\sigma(x)=(1+e^{-x})^{-1}\\).\n\nContrastive margin loss (geometric)\n\n\\[\n\\mathcal L_{\\mathrm{ctr}}(\\theta) = \\sum_{(i,j)\\in\\mathcal P} d_{ij}\n+ \\mu \\sum_{(i,j)\\in\\mathcal N} \\bigl[m - d_{ij}\\bigr]_+ + \\lambda_{\\mathrm{reg}} R(\\theta),\n\\]\nwith \\([x]_+=\\max(0,x)\\).\n\nCombined objective\n\n\\[\n\\mathcal L(\\theta) = \\lambda_{\\mathrm{CE}} \\mathcal L_{\\mathrm{CE}}(\\theta)\n+ \\lambda_{\\mathrm{ctr}} \\mathcal L_{\\mathrm{ctr}}(\\theta)\n+ \\lambda_{\\mathrm{reg}} R(\\theta).\n\\]\nTune \\(\\lambda_{\\mathrm{CE}},\\lambda_{\\mathrm{ctr}},\\lambda_{\\mathrm{reg}}\\) on validation data.\n\n\n\n\nTraining and optimization\n\nMixed discrete‚Äìcontinuous search\n\nSearch space: treat categorical axes as discrete branches and write the global space as a disjoint, tagged union\n\n\\[\n\\Theta=\\bigsqcup_{c\\in\\mathcal C}\\{c\\}\\times\\Theta_c,\n\\]\nso each candidate is a pair \\((c,\\phi)\\) with \\(\\phi\\in\\Theta_c\\).\n\nTwo‚Äëstage search\n\nCoarse screening (parallel, low fidelity): randomized trials across categorical choices with short training, downsampled data, or smaller models. Use Hyperband / successive halving to allocate budget adaptively. Record cheap validation metrics and complexity proxies (params, FLOPs, latency).\nFocused optimization (per branch): for top‚Äë\\(k\\) branches run full gradient‚Äëbased optimization on \\(\\theta_c\\); tune hyperparameters with TPE (Optuna TPESampler) or Bayesian optimization; early stop on held‚Äëout segments; optionally warm‚Äëstart from coarse runs.\n\nOptional joint relaxation: use Gumbel‚ÄëSoftmax / Concrete relaxations (straight‚Äëthrough variant recommended) during coarse training; discretize and re‚Äëevaluate selected branches.\n\n\n\nWithin‚Äëbranch optimization\n\nAutodiff: compute gradients through \\(\\Phi_\\theta\\) and the chosen differentiable objective (soft‚Äëlag or soft‚ÄëDTW).\n\nManifold constraints: if \\(\\Theta_c\\) has constraints, use Riemannian updates (project Euclidean gradient to tangent space, retract) or parametrize constrained variables.\n\nPositivity constraints: parametrize positive scalars as exponentials (e.g., \\(w=\\exp(\\eta)\\), \\(\\tau=\\exp(\\zeta)\\)).\n\n\n\nBatching and negative mining\n\nBalanced minibatches: ensure multiple positives per anchor and controlled negatives; denote \\(\\mathcal P_{\\text{batch}},\\mathcal N_{\\text{batch}}\\).\n\nSemi‚Äëhard negative mining (default): select negatives satisfying \\(d(a,p) &lt; d(a,n) &lt; d(a,p)+m\\); if none, use hardest in‚Äëbatch negative. This yields informative gradients while avoiding extreme noisy outliers.\n\nScaling DTW: reduce \\(O(T^2)\\) cost via downsampling, windowed DTW (Sakoe‚ÄìChiba), low‚Äëdim projections (PCA), or caching repeated distances.\n\n\n\n\n\nRegularization, safeguards, and evaluation\n\nRegularizers and safeguards\n\nEnergy constraint (prevent collapse):\n\n\\[\n\\frac{1}{T}\\sum_{t=1}^T \\|z^\\theta(t)\\|^2 \\ge \\varepsilon,\n\\]\nor add soft penalty \\(\\lambda_{\\text{energy}}\\max\\bigl(0,\\varepsilon - \\tfrac{1}{T}\\sum_t\\|z^\\theta(t)\\|^2\\bigr)\\).\n\nTemporal penalties: \\(\\ell_2\\) smoothness \\(\\sum_t\\|z(t+1)-z(t)\\|^2\\); optional \\(\\ell_1\\) on first differences for sparse transients.\n\nComplexity penalty: \\(C(c,\\theta_c)\\) to penalize FLOPs, parameter count, long filters.\n\nValidation and early stopping: use held‚Äëout segments and cross‚Äësubject splits; monitor validation gap.\n\nRobustness checks: sensitivity to padding, filter length, and categorical axes; run single‚Äëaxis ablations.\n\n\n\nEvaluation protocol\n\nDenoising: Signal-to-noise ratio (SNR), Mean squared error (MSE) on emotion‚Äërelevant bands (use synthetic injections if no ground truth).\n\nAlignment: average soft‚Äëlag correlation \\(\\widetilde\\rho\\) for within‚Äë vs between‚Äësegment pairs.\n\nPairwise classification: accuracy, ROC AUC, precision/recall on held‚Äëout pairs; calibration for logistic models.\n\nEvent detection: precision/recall and temporal localization error for transients.\n\nGeneralization: cross‚Äësession and cross‚Äësubject performance; report validation gap and complexity vs performance.\n\nAblations: effect of categorical choices, regularizers, smoothing \\(\\gamma\\), and temperatures (\\(\\beta,\\tau\\)).\n\n\n\n\n\nImplementation pseudocode\n# Stage A: coarse screening (parallel)\nfor c in categorical_configs:            # parallelizable\n    for r in range(N_random_inits):\n        theta = sample_random_init(c)\n        train_short(theta, data_downsampled)   # few epochs, small model\n        val_metric = evaluate(theta, val_set_small)\n        record_result(c, theta, val_metric)\nC_top = select_top_k_configs()\n\n# Stage B: focused optimization (per selected branch)\nfor c in C_top:\n    theta = initialize_theta(c)           # optional warmstart\n    for epoch in range(1, N_epochs+1):\n        for batch in data_loader:\n            X = batch.recordings\n            Z = Phi_theta(X)              # forward: E_theta, Omega_theta, Psi_theta\n            P_batch, N_batch = sample_pairs(batch, strategy='balanced')\n            if objective == 'lagged_corr':\n                rho_tilde = compute_soft_lag(Z, P_batch, beta)\n                L_obj = -rho_tilde.mean() + lambda_reg * R(theta)\n            elif objective == 'dtw':\n                D_pos = soft_dtw_pairwise(Z, P_batch, gamma)\n                D_neg = soft_dtw_pairwise(Z, N_batch, gamma)\n                L_ctr = D_pos.sum() + mu * torch.relu(m - D_neg).sum()\n                logits = alpha - w * torch.cat([D_pos, D_neg]) / tau\n                L_ce = cross_entropy(torch.sigmoid(logits), labels_for_pairs)\n                L_obj = lambda_ce * L_ce + lambda_ctr * L_ctr + lambda_reg * R(theta)\n            L_obj.backward()              # autodiff through soft-DTW / soft-lag -&gt; Phi_theta\n            if manifold_constraints:\n                g = get_euclidean_grad(theta)\n                g_tangent = project_to_tangent(g, theta)\n                theta = retraction_step(theta, g_tangent, optimizer)\n            else:\n                optimizer.step()\n                optimizer.zero_grad()\n        if early_stop_condition(evaluate(theta, val_set)):\n            break\n    save_checkpoint(theta, c)",
    "crumbs": [
      "Methodology",
      "Extract denoised emotional signals"
    ]
  },
  {
    "objectID": "methodology/embeddings.html",
    "href": "methodology/embeddings.html",
    "title": "Compute heatmap embeddings",
    "section": "",
    "text": "Let \\(X\\in\\mathbb{R}^{I\\times J\\times T}\\) denote a time series of facial heatmaps with spatial size \\(I\\times J\\) and temporal length \\(T\\). We consider three operators applied in cascade:\n\nSpatial embedding (framewise)\n\\(\\mathcal{E}:\\mathbb{R}^{I\\times J}\\to\\mathbb{R}^{K}\\), applied to each frame \\(x_t\\), producing \\(\\mathcal{E}(X)\\in\\mathbb{R}^{K\\times T}\\).\nPer‚Äëchannel 1D DWT and band reconstruction\n\\(\\Omega:\\mathbb{R}^{K\\times T}\\to\\mathbb{R}^{K\\times T}\\), applying a 1D discrete wavelet transform to each channel, selecting bands, and reconstructing.\nNonlinear ICA / dimensionality reduction\n\\(\\Psi:\\mathbb{R}^{K\\times T}\\to\\mathbb{R}^{L\\times T}\\) with \\(L&lt;K\\), applied framewise or on short windows.\n\nDefine the composed map \\[\nf=\\Psi\\circ\\Omega\\circ\\mathcal{E}\\colon \\mathbb{R}^{I\\times J\\times T}\\to\\mathbb{R}^{L\\times T}\\enspace.\n\\] The function space is \\[\n\\mathcal{F}=\\{\\,f:\\mathbb{R}^{I\\times J\\times T}\\to\\mathbb{R}^{L\\times T}\\mid f=\\Psi\\circ\\Omega\\circ\\mathcal{E}\\ \\text{for admissible }\\mathcal{E},\\Omega,\\Psi\\,\\}.\n\\]",
    "crumbs": [
      "Methodology",
      "Compute heatmap embeddings"
    ]
  },
  {
    "objectID": "methodology/embeddings.html#function-space-generated-by-the-composition-of-embedding-wavelet-band-reconstruction-and-nonlinear-ica",
    "href": "methodology/embeddings.html#function-space-generated-by-the-composition-of-embedding-wavelet-band-reconstruction-and-nonlinear-ica",
    "title": "Compute heatmap embeddings",
    "section": "",
    "text": "Let \\(X\\in\\mathbb{R}^{I\\times J\\times T}\\) denote a time series of facial heatmaps with spatial size \\(I\\times J\\) and temporal length \\(T\\). We consider three operators applied in cascade:\n\nSpatial embedding (framewise)\n\\(\\mathcal{E}:\\mathbb{R}^{I\\times J}\\to\\mathbb{R}^{K}\\), applied to each frame \\(x_t\\), producing \\(\\mathcal{E}(X)\\in\\mathbb{R}^{K\\times T}\\).\nPer‚Äëchannel 1D DWT and band reconstruction\n\\(\\Omega:\\mathbb{R}^{K\\times T}\\to\\mathbb{R}^{K\\times T}\\), applying a 1D discrete wavelet transform to each channel, selecting bands, and reconstructing.\nNonlinear ICA / dimensionality reduction\n\\(\\Psi:\\mathbb{R}^{K\\times T}\\to\\mathbb{R}^{L\\times T}\\) with \\(L&lt;K\\), applied framewise or on short windows.\n\nDefine the composed map \\[\nf=\\Psi\\circ\\Omega\\circ\\mathcal{E}\\colon \\mathbb{R}^{I\\times J\\times T}\\to\\mathbb{R}^{L\\times T}\\enspace.\n\\] The function space is \\[\n\\mathcal{F}=\\{\\,f:\\mathbb{R}^{I\\times J\\times T}\\to\\mathbb{R}^{L\\times T}\\mid f=\\Psi\\circ\\Omega\\circ\\mathcal{E}\\ \\text{for admissible }\\mathcal{E},\\Omega,\\Psi\\,\\}.\n\\]",
    "crumbs": [
      "Methodology",
      "Compute heatmap embeddings"
    ]
  },
  {
    "objectID": "methodology/embeddings.html#typical-assumptions",
    "href": "methodology/embeddings.html#typical-assumptions",
    "title": "Compute heatmap embeddings",
    "section": "Typical assumptions",
    "text": "Typical assumptions\n\nRegularity of \\(\\mathcal{E}\\): linear or smooth (PCA, moments, or differentiable neural embedding).\n\nWavelet properties: \\(\\Omega\\) denotes the 1D discrete wavelet analysis followed by optional subband selection and synthesis. Selecting or zeroing coefficients (i.e., discarding subbands) is a projection in coefficient space and in general destroys invertibility; the reconstructed signal is then the band‚Äëlimited approximation obtained from the retained subbands.\nNonlinear ICA identifiability: \\(\\Psi\\) trained with auxiliary/temporal structure enabling identifiability.",
    "crumbs": [
      "Methodology",
      "Compute heatmap embeddings"
    ]
  },
  {
    "objectID": "methodology/embeddings.html#analytic-and-geometric-properties",
    "href": "methodology/embeddings.html#analytic-and-geometric-properties",
    "title": "Compute heatmap embeddings",
    "section": "Analytic and geometric properties",
    "text": "Analytic and geometric properties\n\nFinite parameterization: \\(\\mathcal{F}\\) is a finite‚Äëdimensional manifold when operators are finitely parameterized:\n\n\n\nLet \\(\\Theta\\subset\\mathbb{R}^p\\) parameterize the stages \\(\\mathcal{E}_{\\theta_E},\\Omega_{\\theta_\\Omega},\\Psi_{\\theta_\\Psi}\\) and define\n\\[\n\\Phi:\\Theta\\to\\mathcal{M},\\qquad \\Phi(\\theta)=\\Psi_{\\theta_\\Psi}\\circ\\Omega_{\\theta_\\Omega}\\circ\\mathcal{E}_{\\theta_E},\n\\]\nwhere \\(\\mathcal{M}\\) is a Banach space of maps (for example \\(C^0\\) or \\(L^2\\) mappings). The induced function class is the image \\(\\Phi(\\Theta)=\\{f_\\theta:\\theta\\in\\Theta\\}\\subset\\mathcal{M}\\). If \\(\\Phi\\) is \\(C^r\\) and an immersion at \\(\\theta\\), then \\(\\Phi(\\Theta)\\) is a \\(p\\)-dimensional \\(C^r\\) submanifold of \\(\\mathcal{M}\\). Parameter redundancies reduce the effective dimension, and nonparametric or infinite‚Äëwidth stages may produce infinite‚Äëdimensional families.\n\n\nBand‚Äëlimited structure: outputs after \\(\\Omega\\) are localized in time‚Äìfrequency.\n\n\n\n\n\n\n\nNote\n\n\n\nTime‚Äëlocalization is useful because it lets you detect, separate, and interpret short, emotion‚Äërelated transients (micro‚Äëevents) from background noise; it improves denoising, feature extraction, and interpretability for time‚Äëvarying facial heatmaps, especially when emotions produce brief thermal signatures.\n\n\n\nDimensionality reduction: effective dimension reduces from \\(K\\times T\\) to \\(L\\times T\\).\n\n\nWe employ a sequencewise encoder \\[\n\\Psi:\\mathbb{R}^{K\\times T}\\to\\mathbb{R}^{L\\times T}\\quad(\\text{or }\\Psi:\\mathbb{R}^{K\\times T}\\to\\mathbb{R}^{L\\times T'}\\ \\text{if temporal downsampling is used}),\n\\] so that the effective spatio‚Äëtemporal degrees of freedom are reduced from \\(K\\times T\\) to \\(L\\times T\\) (or \\(L\\times T'\\)). This formulation lets \\(\\Psi\\) exploit temporal dependencies for identifiability and for isolating emotion‚Äërelevant transients while compressing redundant or noisy dimensions.\n\n\nIdentifiability constraints: independence assumptions carve out identifiable latent subspaces.\n\n\n\n\n\n\n\nNote\n\n\n\nIndependence (or conditional‚Äëindependence) assumptions are the mechanism that restrict the space of possible latent explanations and thereby make certain nonlinear‚ÄëICA problems identifiable: they ‚Äúcarve out‚Äù a subspace (or quotient) of latent solutions that can be uniquely recovered up to trivial indeterminacies.",
    "crumbs": [
      "Methodology",
      "Compute heatmap embeddings"
    ]
  },
  {
    "objectID": "python-example.html",
    "href": "python-example.html",
    "title": "Python Example",
    "section": "",
    "text": "This example has some Python code that will be a part of our Quarto site.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\nFigure¬†1: A line plot on a polar axis"
  },
  {
    "objectID": "python-example.html#introduction",
    "href": "python-example.html#introduction",
    "title": "Python Example",
    "section": "",
    "text": "This example has some Python code that will be a part of our Quarto site.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\nFigure¬†1: A line plot on a polar axis"
  },
  {
    "objectID": "project-proposals/explainable-dl.html",
    "href": "project-proposals/explainable-dl.html",
    "title": "Explainable Deep Learning",
    "section": "",
    "text": "This task builds on the results of the Time series modelling. Specifically, it requires a well trained time series model, the accuracy of which supports our hypothesis of a causal association between musical stimuli and brain activity.\nThe aim is to estimate the quality of the causal association by applying techniques of explainable deep learning. The goal is to understand the model‚Äôs decision-making process and to identify the most important features that influence the model‚Äôs predictions. This could lead to an improved understanding of the underlying causal mechanisms and identification of strong/main musical triggers of brain activity.",
    "crumbs": [
      "Task proposals",
      "Explainable DL"
    ]
  },
  {
    "objectID": "project-proposals/explainable-dl.html#problem-statement",
    "href": "project-proposals/explainable-dl.html#problem-statement",
    "title": "Explainable Deep Learning",
    "section": "",
    "text": "This task builds on the results of the Time series modelling. Specifically, it requires a well trained time series model, the accuracy of which supports our hypothesis of a causal association between musical stimuli and brain activity.\nThe aim is to estimate the quality of the causal association by applying techniques of explainable deep learning. The goal is to understand the model‚Äôs decision-making process and to identify the most important features that influence the model‚Äôs predictions. This could lead to an improved understanding of the underlying causal mechanisms and identification of strong/main musical triggers of brain activity.",
    "crumbs": [
      "Task proposals",
      "Explainable DL"
    ]
  },
  {
    "objectID": "project-proposals/explainable-dl.html#suggestions",
    "href": "project-proposals/explainable-dl.html#suggestions",
    "title": "Explainable Deep Learning",
    "section": "Suggestions",
    "text": "Suggestions\nConsider using the following techniques:\n\nClass activation maps (CAM) to visualize the most important regions of the input data (in music state space) that contribute to the model‚Äôs prediction (in facial temperature features state space).\nPerturbation based methods to evaluate the robustness of the model‚Äôs predictions. For example, perturb the input data and observe how the model‚Äôs predictions change. This could help identify the most sensitive regions of the input data.\nAttention weights visualization to provide insights into which parts of the input the model is paying attention to.\nTrend and Seasonal Decomposition: Autoformer model, for example, uses decomposition layers to separate trend and seasonal components. Visualizing these components can help understand how the model captures different aspects of the time-series data.",
    "crumbs": [
      "Task proposals",
      "Explainable DL"
    ]
  },
  {
    "objectID": "project-proposals/time-series-modelling.html",
    "href": "project-proposals/time-series-modelling.html",
    "title": "Time Series Modelling",
    "section": "",
    "text": "We propose a hypothesis suggesting a causal association between two stochastic processes, each operating within its own distinct state space with differing dimensions. The first process involves thermocamera video capturing faces, while the second involves music recording.\nThe aim is to estimate the intensity of the causal association by comparing the self-forecasting of the first process with its forecasting that also incorporates insights from the second process. If the latter demonstrates superior performance, it could indicate a causal association between the two processes.1",
    "crumbs": [
      "Task proposals",
      "Time series modelling"
    ]
  },
  {
    "objectID": "project-proposals/time-series-modelling.html#problem-statement",
    "href": "project-proposals/time-series-modelling.html#problem-statement",
    "title": "Time Series Modelling",
    "section": "",
    "text": "We propose a hypothesis suggesting a causal association between two stochastic processes, each operating within its own distinct state space with differing dimensions. The first process involves thermocamera video capturing faces, while the second involves music recording.\nThe aim is to estimate the intensity of the causal association by comparing the self-forecasting of the first process with its forecasting that also incorporates insights from the second process. If the latter demonstrates superior performance, it could indicate a causal association between the two processes.1",
    "crumbs": [
      "Task proposals",
      "Time series modelling"
    ]
  },
  {
    "objectID": "project-proposals/time-series-modelling.html#suggestions",
    "href": "project-proposals/time-series-modelling.html#suggestions",
    "title": "Time Series Modelling",
    "section": "Suggestions",
    "text": "Suggestions\nWe suggest using a long sequence time forecasting model with a transformer architecture, which has proven effective in handling complex time dependencies in time series data. Specifically, Autoformer and Informer are hot candidates: they are both open source, available on HuggingFace Hub of Git-based repos, and can be relatively easily adapted to our needs.\nNote that causal inference assumes unconfoundedness of the two processes. In general, unconfoundedness is a strong assumption necessary for making causal inferences. However, in our case, it is a reasonable assumption, excluding hidden variables that significantly influence both processes. For example, a potential confounder could be tiredness if it strongly impacts both the opera director/singers/musicians and the audience. In such case, we would need to adjust for it, which is a standard approach in causal inference from observational data.",
    "crumbs": [
      "Task proposals",
      "Time series modelling"
    ]
  },
  {
    "objectID": "project-proposals/time-series-modelling.html#footnotes",
    "href": "project-proposals/time-series-modelling.html#footnotes",
    "title": "Time Series Modelling",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is supported by chain rule for entropy: \\(H(X)=I(X;Y)+H(X‚à£Y)\\), and rests also on the assumption that an opera performance is highly unlikely to be influenced by its audience.‚Ü©Ô∏é",
    "crumbs": [
      "Task proposals",
      "Time series modelling"
    ]
  }
]